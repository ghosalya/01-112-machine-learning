{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning - Project\n",
    "**Gede Ria Ghosalya - 1001841**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part II_\n",
    "+ Write a function that estimates the emission parameters from the training set using MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "\n",
    "def read_labeled_file(filename):\n",
    "    result = []\n",
    "    singletweet = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line == \"\\n\":\n",
    "                result.append(singletweet)\n",
    "                singletweet = []\n",
    "            else:\n",
    "                singletweet.append(tuple(line.strip(\"\\n\").split(\" \")))\n",
    "    return result\n",
    "            \n",
    "# data = read_labeled_file(\"EN/train\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_param(data):\n",
    "    label_to_word_count = {}\n",
    "    word_count = {}\n",
    "    label_count = {}\n",
    "    \n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            if labeled_word[0] in word_count:\n",
    "                word_count[labeled_word[0]] += 1\n",
    "            else:\n",
    "                word_count[labeled_word[0]] = 1\n",
    "                \n",
    "            if labeled_word[1] in label_count:\n",
    "                label_count[labeled_word[1]] += 1\n",
    "            else:\n",
    "                label_count[labeled_word[1]] = 1\n",
    "                \n",
    "            if labeled_word in label_to_word_count:\n",
    "                label_to_word_count[labeled_word] += 1\n",
    "            else:\n",
    "                label_to_word_count[labeled_word] = 1\n",
    "                \n",
    "    emission_parameter = {k: label_to_word_count[k]/label_count[k[1]] \n",
    "                          for k in label_to_word_count}\n",
    "    \n",
    "    return word_count.keys(), label_count.keys(), emission_parameter\n",
    "\n",
    "# words, labels, param = estimate_emission_param(data)\n",
    "# print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  One problem with estimating the emission parameters is that some words that appear in the\n",
    "test set do not appear in the training set. One simple idea to handle this issue is as follows. First,\n",
    "replace those words that appear less than k times in the training set with a special token #UNK#\n",
    "before training. This leads to a “modified training set”. We then use such a modified training set to\n",
    "train our model.\n",
    "During the testing phase, if the word does not appear in the “modified training set”, we replace that\n",
    "word with #UNK# as well.\n",
    "Set k to 3, implement this fix into your function for computing the emission parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supress_infrequent_words(data, k=3):\n",
    "    wordcount = {}\n",
    "    \n",
    "    #get word count\n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            word = labeled_word[0]\n",
    "            if word in wordcount:\n",
    "                wordcount[word] += 1\n",
    "            else:\n",
    "                wordcount[word] = 1\n",
    "                \n",
    "    #generate new list\n",
    "    result = []\n",
    "    newtweet = []\n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            word = labeled_word[0]\n",
    "            if wordcount[word] > k:\n",
    "                newtweet.append(labeled_word)\n",
    "            else:\n",
    "                label = labeled_word[1]\n",
    "                newtweet.append((\"#UNK#\",label))\n",
    "        result.append(newtweet)\n",
    "        newtweet = []\n",
    "        \n",
    "    return result\n",
    "\n",
    "# sdata = supress_infrequent_words(data)\n",
    "# words, labels, em_param = estimate_emission_param(sdata)\n",
    "# print(em_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Implement a simple sentiment analysis system that produces the tag for each word x in the sequence.\n",
    "For all the four datasets EN, FR, CN, and SG, learn these parameters with train, and evaluate your\n",
    "system on the development set dev.in for each of the dataset. Write your output to dev.p2.out\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in dev.out\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sentiment_analysis(labels, param, word):\n",
    "    mle = (word, \"O\") #assuming label O for undiscovered word\n",
    "    mle_value = 0\n",
    "    for l in labels:\n",
    "        if (word, l) in param:\n",
    "            if param[(word, l)] > mle_value:\n",
    "                mle = (word, l)\n",
    "                mle_value = param[(word, l)]\n",
    "    return mle\n",
    "\n",
    "\n",
    "def write_simple_prediction(country, part, words, labels, param):\n",
    "    input_filename = country + \"/dev.in\"\n",
    "    output_filename = country + \"/dev.p\"+part+\".out\"\n",
    "    with open(input_filename, \"r\") as inputfile:\n",
    "        with open(output_filename, \"w\") as outputfile:\n",
    "            for line in inputfile:\n",
    "                if line.strip(\"\\n\") in words:\n",
    "                    pred = single_sentiment_analysis(labels, param, line.strip(\"\\n\"))\n",
    "                    outputfile.write(\" \".join(pred)+\"\\n\")\n",
    "                else:\n",
    "                    outputfile.write(\"#UNK# O\\n\")\n",
    "\n",
    "# write_simple_prediction(\"EN\",\"2\",\n",
    "#                         words, labels, em_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN part 2 done in 0.171915s\n",
      "EN part 2 done in 0.79357s\n",
      "SG part 2 done in 0.310790s\n",
      "FR part 2 done in 0.85036s\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for c in [\"CN\", \"EN\", \"SG\", \"FR\"]:\n",
    "    start = datetime.now()\n",
    "    data = read_labeled_file(c+\"/train\")\n",
    "    sdata = supress_infrequent_words(data)\n",
    "    words, labels, em_param = estimate_emission_param(sdata)\n",
    "    write_simple_prediction(c,\"2\",\n",
    "                    words, labels, em_param)\n",
    "    end = datetime.now()\n",
    "    delt = end - start\n",
    "    print(\"{} part 2 done in {}.{}s\"\\\n",
    "          .format(c, delt.seconds, delt.microseconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Part III_\n",
    "\n",
    "+ Write a function that estimates the transition parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_parameter(data):\n",
    "    y0 = \"START\"\n",
    "    yn = \"STOP\"\n",
    "    label_to_label_count = {}\n",
    "    label_count = {y0: 0, yn: 0}\n",
    "    for tweet in data:\n",
    "        aptweet = tweet + [yn]\n",
    "        for i in range(len(aptweet)):\n",
    "            label = aptweet[i][1]\n",
    "            if label in label_count:\n",
    "                label_count[label] += 1\n",
    "            else:\n",
    "                label_count[label] = 1\n",
    "                \n",
    "            if i == 0:\n",
    "                label_count[y0] += 1\n",
    "                labelt = (y0, label)\n",
    "            else:\n",
    "                prevlabel = aptweet[i-1][1]\n",
    "                labelt = (prevlabel, label)\n",
    "            \n",
    "            if labelt in label_to_label_count:\n",
    "                label_to_label_count[labelt] += 1\n",
    "            else:\n",
    "                label_to_label_count[labelt] = 1\n",
    "    estimated_param = {k: label_to_label_count[k]/label_count[k[0]]\n",
    "                       for k in label_to_label_count}\n",
    "    return estimated_param\n",
    "\n",
    "# trans_param = estimate_transition_parameter(sdata)\n",
    "# print(trans_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use the estimated transition and emission parameters, implement the Viterbi algorithm. For all datasets, learn the model parameters with train. Run the Viterbi algorithm on the development\n",
    "set dev.in using the learned models, write your output to dev.p3.out for the four datasets\n",
    "respectively. Report the precision, recall and F scores of all systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dictionary \n",
    "#   a dictionary consists of\n",
    "#    stage = int (stage 0, 1, 2 etc)\n",
    "#    cur_label = current state (X,Y etc)\n",
    "#    path = path up to this label (eg [START, X, Y])\n",
    "#    probability = float (0.23)\n",
    "        \n",
    "def predict_tag_sequence(word_sequence, \n",
    "                         labels,trans_param,em_param):\n",
    "    pi_dp = {(0, \"START\"):1}\n",
    "    labels = list(labels)\n",
    "    labels.append(\"START\")\n",
    "    \n",
    "    def viterbi_pi(stage, tag, word_sequence,\n",
    "                   labels, trans_param, em_param):\n",
    "        if stage == 0:\n",
    "            result = 1.0 if tag == \"START\" else 0.0\n",
    "            return result\n",
    "        elif stage >= len(word_sequence)+1:\n",
    "            max_weight = 0\n",
    "            for prev_tag in labels:\n",
    "                prev_cost = viterbi_pi(stage-1, prev_tag, word_sequence,\n",
    "                                      labels, trans_param, em_param)\n",
    "                trans_prob = trans_param[(prev_tag, tag)]\n",
    "                curr_weight = prev_cost*trans_prob\n",
    "                if max_weight < curr_weight:\n",
    "                    max_weight = curr_weight\n",
    "            pi_dp[(stage, tag)] = max_weight\n",
    "            return max_weight\n",
    "        else:\n",
    "            if (stage, tag) in pi_dp:\n",
    "                return pi_dp[(stage, tag)]\n",
    "            else:\n",
    "                max_weight = 0\n",
    "                for prev_tag in labels:\n",
    "                    prev_cost = viterbi_pi(stage-1, prev_tag, word_sequence,\n",
    "                                          labels, trans_param, em_param)\n",
    "                    if (prev_tag, tag) in trans_param:\n",
    "                        trans_prob = trans_param[(prev_tag, tag)]\n",
    "                    else:\n",
    "                        trans_prob = 0\n",
    "                    word = word_sequence[stage-1]\n",
    "                    if (word, tag) in em_param:\n",
    "                        em_prob = em_param[(word, tag)]\n",
    "                    else:\n",
    "                        em_prob = 0\n",
    "                    curr_weight = prev_cost*trans_prob*em_prob\n",
    "                    if max_weight < curr_weight:\n",
    "                        max_weight = curr_weight\n",
    "                pi_dp[(stage, tag)] = max_weight\n",
    "                return max_weight\n",
    "\n",
    "    \n",
    "    for i in range(len(word_sequence)):\n",
    "        for t in labels:\n",
    "            viterbi_pi(i, t, word_sequence, \n",
    "                       labels, trans_param, em_param)\n",
    "    \n",
    "    tag_seqr = [\"STOP\"]\n",
    "    \n",
    "    lenw = len(word_sequence)\n",
    "    for i in range(lenw+1):\n",
    "        if i == lenw:\n",
    "            tag_seqr.append(\"START\")\n",
    "            continue\n",
    "        if \"none\" in labels:\n",
    "            max_tag = \"none\"\n",
    "        else:\n",
    "            max_tag = \"O\"\n",
    "        max_weight = 0\n",
    "        for tag in labels:\n",
    "            prev_prob = viterbi_pi(lenw-i, tag, word_sequence,\n",
    "                                   labels, trans_param, em_param)\n",
    "            next_tag = tag_seqr[-1]\n",
    "            if (tag, next_tag) in trans_param:\n",
    "                trans_prob = trans_param[(tag, next_tag)]\n",
    "            else:\n",
    "                trans_prob = 0\n",
    "            curr_weight = prev_prob*trans_prob\n",
    "            if max_weight < curr_weight:\n",
    "                max_weight = curr_weight\n",
    "                max_tag = tag\n",
    "        tag_seqr.append(max_tag)\n",
    "    return tag_seqr[::-1]\n",
    "\n",
    "\n",
    "# word_sequence = [\"we\",\"like\",\"the\",\"ambience\"]\n",
    "# print(predict_tag_sequence(word_sequence))\n",
    "# print(pi_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN part 3 done in 0.708952s\n",
      "EN part 3 done in 0.393983s\n",
      "SG part 3 done in 2.262295s\n",
      "FR part 3 done in 0.343450s\n"
     ]
    }
   ],
   "source": [
    "def write_hmm_prediction(country, part, prediction_function,\n",
    "                         words, labels, em_param, trans_param):\n",
    "    input_filename = country + \"/dev.in\"\n",
    "    output_filename = country + \"/dev.p\"+part+\".out\"\n",
    "    indata = []\n",
    "    with open(input_filename, \"r\") as infile:\n",
    "        indata = infile.read().strip('\\n').split('\\n\\n') #read and separate tweets\n",
    "    \n",
    "    with open(output_filename, \"w\") as outfile:\n",
    "        for tweet in indata:\n",
    "            word_sequence = tweet.split('\\n')\n",
    "            predicted_tag = prediction_function(word_sequence, labels, trans_param, em_param)\n",
    "            predicted_tag.remove(\"START\")\n",
    "            predicted_tag.remove(\"STOP\")\n",
    "            if len(word_sequence) != len(predicted_tag):\n",
    "                print(\"WARNING!! Different length {} / {}\"\\\n",
    "                      .format(word_sequence, tag_sequence))\n",
    "            for i in range(len(word_sequence)):\n",
    "                line = \"{} {}\\n\".format(word_sequence[i], predicted_tag[i])\n",
    "                outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "\n",
    "for c in [\"CN\", \"EN\", \"SG\", \"FR\"]:\n",
    "    start = datetime.now()\n",
    "    data = read_labeled_file(c+\"/train\")\n",
    "    sdata = supress_infrequent_words(data)\n",
    "    words, labels, em_param = estimate_emission_param(sdata)\n",
    "    trans_param = estimate_transition_parameter(sdata)\n",
    "    write_hmm_prediction(c,\"3\", predict_tag_sequence,\n",
    "                        words, labels, em_param, trans_param)\n",
    "    end = datetime.now()\n",
    "    delt = end - start\n",
    "    print(\"{} part 3 done in {}.{}s\"\\\n",
    "          .format(c, delt.seconds, delt.microseconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Part IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use the estimated transition and emission parameters, implement the alternative max-marginal decoding algorithm. Clearly describe the steps of your algorithm in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = {}\n",
    "\n",
    "def alpha_forward(tag, stage, word_sequence, alphas,\n",
    "                  trans_param=trans_param,\n",
    "                  labels=labels,\n",
    "                  em_param=em_param):\n",
    "    '''\n",
    "    Forward algorithm\n",
    "    '''\n",
    "    if stage <= 1:\n",
    "        if (\"START\", tag) in trans_param:\n",
    "            score = trans_param[(\"START\", tag)]\n",
    "        else:\n",
    "            score = 0\n",
    "        alphas[(tag, stage)] = score\n",
    "        return score\n",
    "    else:\n",
    "        if (tag, stage) in alphas:\n",
    "            return alphas[(tag, stage)]\n",
    "        score = 0\n",
    "        for t in labels:\n",
    "            prev_score = alpha_forward(t, stage-1, word_sequence, alphas)\n",
    "            if (t, tag) in trans_param:\n",
    "                trans_prob = trans_param[(t, tag)]\n",
    "            else:\n",
    "                trans_prob = 0\n",
    "            word = word_sequence[stage-2]\n",
    "            if (word, t) in em_param:\n",
    "                em_prob = em_param[(word, t)]\n",
    "            else:\n",
    "                em_prob = 0\n",
    "            curr_score = prev_score*trans_prob*em_prob\n",
    "            score += curr_score\n",
    "        alphas[(tag, stage)] = score\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betas = {}\n",
    "\n",
    "def beta_back(tag, stage, word_sequence, betas,\n",
    "                  trans_param=trans_param,\n",
    "                  labels=labels,\n",
    "                  em_param=em_param):\n",
    "    '''\n",
    "    Backward algorithm\n",
    "    '''\n",
    "    if stage <= 1:\n",
    "        if (tag, \"STOP\") in trans_param:\n",
    "            score = trans_param[(tag, \"STOP\")]\n",
    "        else:\n",
    "            score = 0\n",
    "        betas[(tag, stage)] = score\n",
    "        return score\n",
    "    else:\n",
    "        if (tag, stage) in betas:\n",
    "            return betas[(tag, stage)]\n",
    "        score = 0\n",
    "        for t in labels:\n",
    "            prev_score = beta_back(t, stage-1, word_sequence, betas)\n",
    "            if (tag, t) in trans_param:\n",
    "                trans_prob = trans_param[(tag, t)]\n",
    "            else:\n",
    "                trans_prob = 0\n",
    "            word = word_sequence[stage-2]\n",
    "            if (word, tag) in em_param:\n",
    "                em_prob = em_param[(word, tag)]\n",
    "            else:\n",
    "                em_prob = 0\n",
    "            curr_score = prev_score*trans_prob*em_prob\n",
    "            score += curr_score\n",
    "        betas[(tag, stage)] = score\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN part 4 done in 0.385215s\n",
      "FR part 4 done in 0.350346s\n"
     ]
    }
   ],
   "source": [
    "def predict_tag_sequence_maxmarginal(word_sequence,\n",
    "                                    labels=labels,\n",
    "                                    trans_param=trans_param,\n",
    "                                    em_param=em_param):\n",
    "    '''\n",
    "    using max-marginal decoding algorithm\n",
    "    '''\n",
    "    alphas = {}\n",
    "    betas = {}\n",
    "    \n",
    "    tag_seqr = [\"STOP\"]\n",
    "    \n",
    "    lenw = len(word_sequence)\n",
    "    for i in range(lenw):\n",
    "        max_tag = \"O\"\n",
    "        max_weight = 0\n",
    "        for tag in labels:\n",
    "            alph = alpha_forward(tag, i, word_sequence, alphas,\n",
    "                                 labels=labels, em_param=em_param, \n",
    "                                 trans_param=trans_param)\n",
    "            beth = beta_back(tag, i, word_sequence, betas,\n",
    "                                 labels=labels, em_param=em_param, \n",
    "                                 trans_param=trans_param)\n",
    "            curr_weight = alph*beth\n",
    "            if curr_weight > max_weight:\n",
    "                max_weight = curr_weight\n",
    "                max_tag = tag\n",
    "        tag_seqr.append(max_tag)\n",
    "    tag_seqr.append(\"START\")\n",
    "    return tag_seqr[::-1]\n",
    "\n",
    "# word_sequence = [\"we\",\"like\",\"the\",\"ambience\"]\n",
    "# print(predict_tag_sequence_maxmarginal(word_sequence))\n",
    "\n",
    "for c in [\"EN\", \"FR\"]:\n",
    "    start = datetime.now()\n",
    "    data = read_labeled_file(c+\"/train\")\n",
    "    sdata = supress_infrequent_words(data)\n",
    "    words, labels, em_param = estimate_emission_param(sdata)\n",
    "    write_hmm_prediction(c,\"4\",\n",
    "                        predict_tag_sequence_maxmarginal,\n",
    "                        words, labels, em_param, trans_param)\n",
    "    end = datetime.now()\n",
    "    delt = end - start\n",
    "    print(\"{} part 4 done in {}.{}s\"\\\n",
    "          .format(c, delt.seconds, delt.microseconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the training and development set, think of a better design for developing an\n",
    "improved sentiment analysis system for tweets using any model you like. Please explain clearly the\n",
    "method that you used for designing the new system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attempt 1: Using dual-tagged HMM\n",
    "\n",
    "There is some rule to the tagging that is not\n",
    "covered by the HMM alone, specifically sentiment\n",
    "vs identity. For example, B-positive cannot be\n",
    "followed by I-negative. \n",
    "\n",
    "Hence, one tag class is sentiment, [positive, negative, neutral, none]\n",
    "and another  is identity [O, B, I]\n",
    "before the observation layer\n",
    "'''\n",
    "\n",
    "# first of all, we want to generate\n",
    "# properly-layered file\n",
    "\n",
    "def split_tag_layer(input_filename, output_filename):\n",
    "    with open(input_filename, \"r\") as infile:\n",
    "        with open(output_filename, \"w\") as outfile:\n",
    "            for inline in infile:\n",
    "                if inline == \"\\n\":\n",
    "                    outfile.write(inline)\n",
    "                    continue\n",
    "                    \n",
    "                line = inline.strip(\"\\n\").split(\" \")\n",
    "                if len(line) < 2:\n",
    "                    pass\n",
    "                elif \"positive\" in line[1]:\n",
    "                    line[1] = line[1][0]\n",
    "                    line.append(\"positive\")\n",
    "                elif \"negative\" in line[1]:\n",
    "                    line[1] = line[1][0]\n",
    "                    line.append(\"negative\")\n",
    "                elif \"neutral\" in line[1]:\n",
    "                    line[1] = line[1][0]\n",
    "                    line.append(\"neutral\")\n",
    "                else:\n",
    "                    line.append(\"none\")\n",
    "                \n",
    "                string = \" \".join(line) + \"\\n\"\n",
    "                outfile.write(string)\n",
    "                \n",
    "split_tag_layer(\"EN/train\", \"EN/trainl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that the file is tagged properly,\n",
    "we can generate estimated parameters\n",
    "\n",
    "Note that while the identity tags [O, B, I] are ordered,\n",
    "sentiments are not - they are not always associated with \n",
    "the identified phares\n",
    "'''\n",
    "\n",
    "def read_splitlabel_file(filename):\n",
    "    sm_emparam = []\n",
    "    sm_tweet = []\n",
    "    id_emparam = []\n",
    "    id_tweet = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line == \"\\n\":\n",
    "                id_emparam.append(id_tweet)\n",
    "                id_tweet = []\n",
    "                sm_emparam.append(sm_tweet)\n",
    "                sm_tweet = []\n",
    "            else:\n",
    "                linetags = line.strip(\"\\n\").split(\" \")\n",
    "                id_tweet.append(tuple([linetags[0], linetags[1]]))\n",
    "                sm_tweet.append(tuple([linetags[0], linetags[2]]))\n",
    "    return sm_emparam, id_emparam\n",
    "\n",
    "sm_data, id_data = read_splitlabel_file(\"EN/trainl\")\n",
    "# print(sm_param)\n",
    "# print(id_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'O', 'O', 'O', 'O', 'STOP']\n",
      "['START', 'none', 'none', 'none', 'none', 'STOP']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Once data is extracted, we can estimate\n",
    "identity (and sentiment) tags with normal HMM methods\n",
    "'''\n",
    "\n",
    "words, labels, id_emparam = estimate_emission_param(id_data)\n",
    "id_transparam = estimate_transition_parameter(id_data)\n",
    "swords, slabels, sm_emparam = estimate_emission_param(sm_data)\n",
    "sm_transparam = estimate_transition_parameter(sm_data)\n",
    "\n",
    "def predict_dualtag_sequence(word_sequence, labels, slabels,\n",
    "                            id_emparam, id_transparam,\n",
    "                            sm_emparam, sm_transparam):\n",
    "    id_tagsequence = predict_tag_sequence(word_sequence, labels,\n",
    "                                          id_transparam, id_emparam)\n",
    "    sm_tagsequence = predict_tag_sequence(word_sequence, slabels,\n",
    "                                          sm_transparam, sm_emparam)\n",
    "    # we do some cleanup\n",
    "    # because in the original, only identities have sentiments\n",
    "    # but the prediction might not be the case\n",
    "    sm_count = {}\n",
    "    for sm in sm_tagsequence:\n",
    "        sm_count[sm] = sm_count.get(sm, 0) + 1\n",
    "        \n",
    "    if \"none\" in sm_count:\n",
    "        del sm_count[\"none\"]\n",
    "    if \"START\" in sm_count:\n",
    "        del sm_count[\"START\"]\n",
    "    if \"STOP\" in sm_count:\n",
    "        del sm_count[\"STOP\"]\n",
    "        \n",
    "    mostcommon = (\"neutral\", 0)\n",
    "    for sm in sm_count:\n",
    "        if sm_count[sm] > mostcommon[1]:\n",
    "            mostcommon = (sm, sm_count[sm])\n",
    "    \n",
    "    for i in range(len(id_tagsequence)):\n",
    "        if id_tagsequence[i] != \"O\" and sm_tagsequence[i] == \"none\":\n",
    "#             print(\" \".join(word_sequence) + \" is problematic..\")\n",
    "#             print(\"adding default \"+mostcommon[0])\n",
    "            sm_tagsequence[i] = mostcommon[0]\n",
    "    \n",
    "    return id_tagsequence, sm_tagsequence\n",
    "\n",
    "word_sequence = [\"we\", \"like\", \"the\", \"ambience\"]\n",
    "id_tagseq, sm_tagseq = predict_dualtag_sequence(word_sequence, labels, slabels,\n",
    "                                               id_emparam, id_transparam,\n",
    "                                               sm_emparam, sm_transparam)\n",
    "print(id_tagseq)\n",
    "print(sm_tagseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN part 5 done in 0.818423s\n",
      "EN part 5 done in 0.433303s\n",
      "SG part 5 done in 2.865688s\n",
      "FR part 5 done in 0.444736s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now, we can write the predictions\n",
    "'''\n",
    "def write_dualhmm_prediction(country, part, prediction_function,\n",
    "                             words, labels, slabels,\n",
    "                             id_emparam, id_transparam,\n",
    "                             sm_emparam, sm_transparam):\n",
    "    input_filename = country + \"/dev.in\"\n",
    "    output_filename = country + \"/dev.p\"+part+\".out\"\n",
    "    indata = []\n",
    "    with open(input_filename, \"r\") as infile:\n",
    "        indata = infile.read().strip('\\n').split('\\n\\n') #read and separate tweets\n",
    "    \n",
    "    with open(output_filename, \"w\") as outfile:\n",
    "        for tweet in indata:\n",
    "            word_sequence = tweet.split('\\n')\n",
    "            pred_id_tag, pred_sm_tag = prediction_function(word_sequence, labels, slabels,\n",
    "                                                id_emparam, id_transparam,\n",
    "                                                sm_emparam, sm_transparam)\n",
    "            pred_id_tag.remove(\"START\")\n",
    "            pred_id_tag.remove(\"STOP\")\n",
    "            pred_sm_tag.remove(\"START\")\n",
    "            pred_sm_tag.remove(\"STOP\")\n",
    "            if len(word_sequence) != len(pred_id_tag):\n",
    "                print(\"WARNING!! Different length \\n{} / \\n{}\"\\\n",
    "                      .format(word_sequence, pred_id_tag))\n",
    "            for i in range(len(word_sequence)):\n",
    "                line = \"{} {} {}\\n\".format(word_sequence[i], pred_id_tag[i], pred_sm_tag[i])\n",
    "                outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "            \n",
    "for c in [\"CN\", \"EN\", \"SG\", \"FR\"]:\n",
    "    start = datetime.now()\n",
    "    split_tag_layer(c+\"/train\", c+\"/trainl\")\n",
    "    sm_data, id_data = read_splitlabel_file(c+\"/trainl\")\n",
    "    sm_data = supress_infrequent_words(sm_data)\n",
    "    id_data = supress_infrequent_words(id_data)\n",
    "    \n",
    "    words, labels, id_emparam = estimate_emission_param(id_data)\n",
    "    id_transparam = estimate_transition_parameter(id_data)\n",
    "    swords, slabels, sm_emparam = estimate_emission_param(sm_data)\n",
    "    sm_transparam = estimate_transition_parameter(sm_data)\n",
    "    \n",
    "    write_dualhmm_prediction(c,\"5l\", predict_dualtag_sequence,\n",
    "                             words, labels, slabels,\n",
    "                             id_emparam, id_transparam,\n",
    "                             sm_emparam, sm_transparam)\n",
    "    end = datetime.now()\n",
    "    delt = end - start\n",
    "    print(\"{} part 5 done in {}.{}s\"\\\n",
    "          .format(c, delt.seconds, delt.microseconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally, we convert back the file\n",
    "to the original format\n",
    "'''\n",
    "def merge_tag_layer(input_filename, output_filename):\n",
    "    with open(input_filename, \"r\") as infile:\n",
    "        with open(output_filename, \"w\") as outfile:\n",
    "            for inline in infile:\n",
    "                if inline == \"\\n\":\n",
    "                    outfile.write(\"\\n\")\n",
    "                    continue\n",
    "                line = inline.strip(\"\\n\").split(\" \")\n",
    "                if line[1] == \"O\":\n",
    "                    string = \" \".join(line[:-1]) + \"\\n\"\n",
    "                else:\n",
    "                    string = \" \".join(line[:-1]) + \"-\"+ line[2] + \"\\n\"\n",
    "                outfile.write(string)\n",
    "                \n",
    "for c in [\"CN\",\"EN\",\"SG\",\"FR\"]:\n",
    "    merge_tag_layer(c+\"/dev.p5l.out\", c+\"/dev.p5.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Comparing this to part3 (HMM with Viterbi)\n",
    " // code taken from EvalScript\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import re\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "#Read entities from predcition\n",
    "def get_predicted(predicted, answers=defaultdict(lambda: defaultdict(defaultdict)),\n",
    "                  separator=\" \",outputColumnIndex=1):\n",
    "\n",
    "    example = 0\n",
    "    word_index = 0\n",
    "    entity = []\n",
    "    last_ne = \"O\"\n",
    "    last_sent = \"\"\n",
    "    last_entity = []\n",
    "\n",
    "    answers[example] = []\n",
    "    for line in predicted:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"##\"):\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            if entity:\n",
    "                answers[example].append(list(entity))\n",
    "                entity = []\n",
    "\n",
    "            example += 1\n",
    "            answers[example] = []\n",
    "            word_index = 0\n",
    "            last_ne = \"O\"\n",
    "            continue\n",
    "        else:\n",
    "            split_line = line.split(separator)\n",
    "            #word = split_line[0]\n",
    "            value = split_line[outputColumnIndex]\n",
    "            ne = value[0]\n",
    "            sent = value[2:]\n",
    "\n",
    "\n",
    "            last_entity = []\n",
    "\n",
    "            #check if it is start of entity\n",
    "            if ne == 'B' or (ne == 'I' and last_ne == 'O') or (last_ne != 'O' and ne == 'I' and last_sent != sent):\n",
    "                if entity:\n",
    "                    last_entity = list(entity)\n",
    "\n",
    "                entity = [sent]\n",
    "                    \n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'I':\n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'O':\n",
    "                if last_ne == 'B' or last_ne == 'I':\n",
    "                    last_entity =list(entity)\n",
    "                entity = []\n",
    "\n",
    "\n",
    "            if last_entity:\n",
    "                answers[example].append(list(last_entity))\n",
    "                last_entity = []\n",
    "\n",
    "        last_sent = sent\n",
    "        last_ne = ne\n",
    "        word_index += 1\n",
    "\n",
    "    if entity:\n",
    "        answers[example].append(list(entity))\n",
    "\n",
    "\n",
    "    return answers\n",
    "\n",
    "\n",
    "\n",
    "#Read entities from gold data\n",
    "def get_observed(observed, separator=\" \",\n",
    "                 outputColumnIndex=1):\n",
    "\n",
    "\n",
    "    example = 0\n",
    "    word_index = 0\n",
    "    entity = []\n",
    "    last_ne = \"O\"\n",
    "    last_sent = \"\"\n",
    "    last_entity = []\n",
    "\n",
    "    observations=defaultdict(defaultdict)\n",
    "    observations[example] = []\n",
    "\n",
    "    for line in observed:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"##\"):\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            if entity:\n",
    "                observations[example].append(list(entity))\n",
    "                entity = []\n",
    "\n",
    "            example += 1\n",
    "            observations[example] = []\n",
    "            word_index = 0\n",
    "            last_ne = \"O\"\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            split_line = line.split(separator)\n",
    "            word = split_line[0]\n",
    "            value = split_line[outputColumnIndex]\n",
    "            ne = value[0]\n",
    "            sent = value[2:]\n",
    "\n",
    "\n",
    "            last_entity = []\n",
    "\n",
    "            #check if it is start of entity, suppose there is no weird case in gold data\n",
    "            if ne == 'B' or (ne == 'I' and last_ne == 'O') or (last_ne != 'O' and ne == 'I' and last_sent != sent):\n",
    "                if entity:\n",
    "                    last_entity = entity\n",
    "\n",
    "                entity = [sent]\n",
    "                    \n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'I':\n",
    "                entity.append(word_index)\n",
    "\n",
    "            elif ne == 'O':\n",
    "                if last_ne == 'B' or last_ne == 'I':\n",
    "                    last_entity = entity\n",
    "                entity = []\n",
    "\n",
    "\n",
    "            if last_entity:\n",
    "                observations[example].append(list(last_entity))\n",
    "                last_entity = []\n",
    "\n",
    "\n",
    "        last_ne = ne\n",
    "        last_sent = sent\n",
    "        word_index += 1\n",
    "\n",
    "    if entity:\n",
    "        observations[example].append(list(entity))\n",
    "    return observations\n",
    "\n",
    "#Compare results bewteen gold data and prediction data\n",
    "def compare_observed_to_predicted(observed, predicted):\n",
    "\n",
    "    correct_sentiment = 0\n",
    "    correct_entity = 0\n",
    "\n",
    "    total_observed = 0.0\n",
    "    total_predicted = 0.0\n",
    "\n",
    "    #For each Instance Index example (example = 0,1,2,3.....)\n",
    "    for example in observed:\n",
    "        observed_instance = observed[example]\n",
    "        predicted_instance = predicted[example]\n",
    "\n",
    "        #Count number of entities in gold data\n",
    "        total_observed += len(observed_instance)\n",
    "        #Count number of entities in prediction data\n",
    "        total_predicted += len(predicted_instance)\n",
    "\n",
    "        #For each entity in prediction\n",
    "        for span in predicted_instance:\n",
    "            span_begin = span[1]\n",
    "            span_length = len(span) - 1\n",
    "            span_ne = (span_begin, span_length)\n",
    "            span_sent = span[0]\n",
    "\n",
    "            #For each entity in gold data\n",
    "            for observed_span in observed_instance:\n",
    "                begin = observed_span[1]\n",
    "                length = len(observed_span) - 1\n",
    "                ne = (begin, length)\n",
    "                sent = observed_span[0]\n",
    "\n",
    "                #Entity matched\n",
    "                if span_ne == ne:\n",
    "                    correct_entity += 1\n",
    "                    \n",
    "\n",
    "                    #Entity & Sentiment both are matched\n",
    "                    if span_sent == sent:\n",
    "                        correct_sentiment += 1\n",
    "\n",
    "    result = []\n",
    "    result.append(total_observed)\n",
    "    result.append(total_predicted)\n",
    "    result.append(correct_entity)\n",
    "    prec = 100*correct_entity/total_predicted\n",
    "    rec = 100*correct_entity/total_observed\n",
    "    result.append(prec) # entity precision\n",
    "    result.append(rec) # entity recall\n",
    "    result.append(correct_sentiment)\n",
    "    prec = 100*correct_sentiment/total_predicted\n",
    "    rec = 100*correct_sentiment/total_observed\n",
    "    result.append(prec) # sentiment precision\n",
    "    result.append(rec) # sentiment recall\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[362.0, 102.0, 33, 32.35294117647059, 9.116022099447514, 24, 23.529411764705884, 6.629834254143646]\n",
      "[362.0, 102.0, 33, 32.35294117647059, 9.116022099447514, 24, 23.529411764705884, 6.629834254143646]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv+E9HOrFIDuZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90970bf4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226.0, 84.0, 67, 79.76190476190476, 29.646017699115045, 40, 47.61904761904762, 17.699115044247787]\n",
      "[226.0, 84.0, 67, 79.76190476190476, 29.646017699115045, 40, 47.61904761904762, 17.699115044247787]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb3BuiPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90ac10cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1382.0, 200.0, 100, 50.0, 7.23589001447178, 71, 35.5, 5.137481910274964]\n",
      "[1382.0, 200.0, 100, 50.0, 7.23589001447178, 71, 35.5, 5.137481910274964]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxaGLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9096a92748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223.0, 92.0, 73, 79.34782608695652, 32.73542600896861, 37, 40.21739130434783, 16.591928251121075]\n",
      "[223.0, 92.0, 73, 79.34782608695652, 32.73542600896861, 37, 40.21739130434783, 16.591928251121075]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsNikCQ1LAZJUuN/AV1OIFhIMh3KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9096abb908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_eval = {}\n",
    "\n",
    "for c in [\"CN\",\"EN\",\"SG\",\"FR\"]:\n",
    "    gold = open(c+\"/dev.out\", \"r\", encoding='UTF-8')\n",
    "    observed = get_observed(gold)\n",
    "    prediction3 = open(c+\"/dev.p3.out\", \"r\", encoding='UTF-8')\n",
    "    predicted3 = get_predicted(prediction3)\n",
    "    prediction5 = open(c+\"/dev.p5.out\", \"r\", encoding='UTF-8')\n",
    "    predicted5 = get_predicted(prediction5)\n",
    "    \n",
    "    resul3 = compare_observed_to_predicted(observed, predicted3)\n",
    "    print(resul3)\n",
    "    resul5 = compare_observed_to_predicted(observed, predicted5)\n",
    "    print(resul5)\n",
    "    resul_diff = [resul5[i] - resul3[i] for i in range(len(resul3))]\n",
    "    x3 = [x for x in range(len(resul3))]\n",
    "#     x5 = [x+0.22 for x in range(len(resul5))]\n",
    "    width = 1\n",
    "#     plt.bar(x3, resul3, width, color=\"blue\")\n",
    "#     plt.bar(x5, resul5, width, color=\"green\")\n",
    "    plt.title(c+\" Comparison\")\n",
    "#     plt.bar(x3, resul_diff)\n",
    "    plt.plot(resul_diff)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
