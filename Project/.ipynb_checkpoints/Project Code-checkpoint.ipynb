{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning - Project\n",
    "**Gede Ria Ghosalya - 1001841**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part II_\n",
    "+ Write a function that estimates the emission parameters from the training set using MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "\n",
    "def read_labeled_file(filename):\n",
    "    result = []\n",
    "    singletweet = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line == \"\\n\":\n",
    "                result.append(singletweet)\n",
    "                singletweet = []\n",
    "            else:\n",
    "                singletweet.append(tuple(line.strip(\"\\n\").split(\" \")))\n",
    "    return result\n",
    "            \n",
    "data = read_labeled_file(\"EN/train\")\n",
    "#print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_param(data):\n",
    "    label_to_word_count = {}\n",
    "    word_count = {}\n",
    "    label_count = {}\n",
    "    \n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            if labeled_word[0] in word_count:\n",
    "                word_count[labeled_word[0]] += 1\n",
    "            else:\n",
    "                word_count[labeled_word[0]] = 1\n",
    "                \n",
    "            if labeled_word[1] in label_count:\n",
    "                label_count[labeled_word[1]] += 1\n",
    "            else:\n",
    "                label_count[labeled_word[1]] = 1\n",
    "                \n",
    "            if labeled_word in label_to_word_count:\n",
    "                label_to_word_count[labeled_word] += 1\n",
    "            else:\n",
    "                label_to_word_count[labeled_word] = 1\n",
    "                \n",
    "    emission_parameter = {k: label_to_word_count[k]/label_count[k[1]] \n",
    "                          for k in label_to_word_count}\n",
    "    \n",
    "    return word_count.keys(), label_count.keys(), emission_parameter\n",
    "\n",
    "words, labels, param = estimate_emission_param(data)\n",
    "#print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  One problem with estimating the emission parameters is that some words that appear in the\n",
    "test set do not appear in the training set. One simple idea to handle this issue is as follows. First,\n",
    "replace those words that appear less than k times in the training set with a special token #UNK#\n",
    "before training. This leads to a “modified training set”. We then use such a modified training set to\n",
    "train our model.\n",
    "During the testing phase, if the word does not appear in the “modified training set”, we replace that\n",
    "word with #UNK# as well.\n",
    "Set k to 3, implement this fix into your function for computing the emission parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supress_infrequent_words(data, k=3):\n",
    "    wordcount = {}\n",
    "    \n",
    "    #get word count\n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            word = labeled_word[0]\n",
    "            if word in wordcount:\n",
    "                wordcount[word] += 1\n",
    "            else:\n",
    "                wordcount[word] = 1\n",
    "                \n",
    "    #generate new list\n",
    "    result = []\n",
    "    newtweet = []\n",
    "    for tweet in data:\n",
    "        for labeled_word in tweet:\n",
    "            word = labeled_word[0]\n",
    "            if wordcount[word] > k:\n",
    "                newtweet.append(labeled_word)\n",
    "            else:\n",
    "                label = labeled_word[1]\n",
    "                newtweet.append((\"#UNK#\",label))\n",
    "        result.append(newtweet)\n",
    "        newtweet = []\n",
    "        \n",
    "    return result\n",
    "\n",
    "sdata = supress_infrequent_words(data)\n",
    "words, labels, param = estimate_emission_param(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Implement a simple sentiment analysis system that produces the tag for each word x in the sequence.\n",
    "For all the four datasets EN, FR, CN, and SG, learn these parameters with train, and evaluate your\n",
    "system on the development set dev.in for each of the dataset. Write your output to dev.p2.out\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in dev.out\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sentiment_analysis(labels, param, word):\n",
    "    mle = (word, \"O\") #assuming label O for undiscovered word\n",
    "    mle_value = 0\n",
    "    for l in labels:\n",
    "        if (word, l) in param:\n",
    "            if param[(word, l)] > mle_value:\n",
    "                mle = (word, l)\n",
    "                mle_value = param[(word, l)]\n",
    "    return mle\n",
    "\n",
    "\n",
    "def write_simple_prediction(input_filename, output_filename, words, labels, param):\n",
    "    with open(input_filename, \"r\") as inputfile:\n",
    "        with open(output_filename, \"w\") as outputfile:\n",
    "            for line in inputfile:\n",
    "                if line.strip(\"\\n\") in words:\n",
    "                    pred = single_sentiment_analysis(labels, param, line.strip(\"\\n\"))\n",
    "                    outputfile.write(\" \".join(pred)+\"\\n\")\n",
    "                else:\n",
    "                    outputfile.write(\"#UNK# O\\n\")\n",
    "\n",
    "write_simple_prediction(\"EN/dev.in\",\n",
    "                        \"EN/dev.p2.out\",\n",
    "                        words, labels, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
